{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc2fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9808ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The cat sat quietly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ec360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: {'The': 0, 'cat': 1, 'sat': 2, 'quietly': 3}\n"
     ]
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "vocab = {word: idx for idx, word in enumerate(tokens)}\n",
    "print(\"Vocab:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad049219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "token_ids = [vocab[token] for token in tokens]\n",
    "print(\"Token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531be059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings:\n",
      " tensor([[-0.7964, -0.6372,  0.8634],\n",
      "        [ 0.0595,  0.3991,  0.5173],\n",
      "        [-0.9806, -0.2280,  0.8676],\n",
      "        [-0.6734,  1.8603,  0.9321]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Creating an embedding layer\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "input_tensor = torch.tensor(token_ids)\n",
    "embedded = embedding(input_tensor)\n",
    "print(\"Embeddings:\\n\", embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32afa922",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings= torch.stack([embedded[i] for i in token_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d458002d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7964, -0.6372,  0.8634],\n",
       "        [ 0.0595,  0.3991,  0.5173],\n",
       "        [-0.9806, -0.2280,  0.8676],\n",
       "        [-0.6734,  1.8603,  0.9321]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5527ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose output_dim = 2 for Q, K, V\n",
    "W_q = torch.rand((3, 2))\n",
    "W_k = torch.rand((3, 2))\n",
    "W_v = torch.rand((3, 2))\n",
    "\n",
    "Q = input_embeddings @ W_q\n",
    "K = input_embeddings @ W_k\n",
    "V = input_embeddings @ W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a57fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Products: tensor([-0.0420,  0.8301,  0.2412,  2.1782], grad_fn=<MvBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's take \"cat\", which is at index 1\n",
    "query_index = 1\n",
    "q_cat = Q[query_index]          \n",
    "dot_products = torch.matmul(K, q_cat)  # Dotproduct with all Keys\n",
    "print(\"Dot Products:\", dot_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b8a076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Dot Products: tensor([-0.0297,  0.5869,  0.1705,  1.5402], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "d_k = Q.size(-1)  # size of each query/key vector = 2\n",
    "scaled_dots = dot_products / math.sqrt(d_k)\n",
    "print(\"Scaled Dot Products:\", scaled_dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9cb404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights: tensor([0.1126, 0.2086, 0.1376, 0.5412], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "attention_weights = F.softmax(scaled_dots, dim=0)\n",
    "print(\"Attention Weights:\", attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b355dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Dot product of Q and K^T\n",
    "dot_products_all = torch.matmul(Q, K.T)  # shape: (4, 4)\n",
    "\n",
    "# Step 2: Scale the dot products\n",
    "dk = Q.shape[-1]\n",
    "scaled_dot_products = dot_products_all / math.sqrt(dk)  # shape: (4, 4)\n",
    "\n",
    "# Step 3: Apply softmax to get attention weights\n",
    "attention_weights_all = F.softmax(scaled_dot_products, dim=1)  # shape: (4, 4)\n",
    "\n",
    "# Step 4: Multiply attention weights with V to get attention output\n",
    "# attention_output[i] = sum_j(attention_weight[i][j] * V[j])\n",
    "attention_output = torch.matmul(attention_weights_all, V)  # shape: (4, 2)\n",
    "\n",
    "# Print each token's final output representation\n",
    "print(\"Attention Output Vectors:\")\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"{token}: {attention_output[i].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5824fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compute weighted sum of value vectors\n",
    "attention_output_cat = torch.sum(attention_weights.unsqueeze(1) * V, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d35daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2068,  1.6595], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e209e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights for 'cat': [0.1126038059592247, 0.20862381160259247, 0.1375701129436493, 0.5412022471427917]\n",
      "Final Attention Output for 'cat': [-0.2068280726671219, 1.6594971418380737]\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention Weights for 'cat':\", attention_weights.tolist())\n",
    "print(\"Final Attention Output for 'cat':\", attention_output_cat.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
